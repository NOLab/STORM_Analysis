{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of STORM images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the dictionary with the values being the folders containing the datasets (each value is the path of the folder corresponding to one type of buffer and containing all the data associated to it). Note that the macro script should be run on the folder before using this code. The keys of the dictionary are the names you would like to give to the directories (label of the buffers).\n",
    "paths = {}\n",
    "\n",
    "# indicate the size of te pixels you want to compute the density (in nanometers)\n",
    "length_nm = 0\n",
    "\n",
    "#indicate the value of the first degree of freedom for each data\n",
    "x_list = []\n",
    "#indicate the value of the second degree of freedom for each data (in the same order)\n",
    "y_list = []\n",
    "# indicate the interval the order of magnitude of variation between the values in x_list (for examples 0.01 if values vary by at least 2 decimals, 1 if the vary by at least 1)\n",
    "x_spacing = 0\n",
    "# Do the same for y\n",
    "y_spacing = 0\n",
    "# Indicate the name of the degree of freedom x\n",
    "x_label = ''\n",
    "# Indicate the unit of the degree of freedom y\n",
    "x_unit = ''\n",
    "# Do the same for y\n",
    "y_label = ''\n",
    "y_unit = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run next cell and then the cells you are interested in. Note that for cells with graphs outputs, you can save the plots by uncommenting the last line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import scipy.optimize\n",
    "import math\n",
    "import scipy.stats\n",
    "import statistics\n",
    "from scipy.interpolate import griddata\n",
    "import os\n",
    "import re\n",
    "\n",
    "number_paths = len(paths) # the number of paths\n",
    "\n",
    "\n",
    "l, l2, l3 = [], [], [] \n",
    "for path in list(paths.values()): \n",
    "    lp1 = os.listdir(path) # list of the files in the path considered\n",
    "    lp1 = list(filter(lambda x: x.endswith('avg.xls'), lp1)) # list of only the names of the files averaged\n",
    "    l2p1 = [os.path.join(path, f) for f in lp1] # list of the directories of the files averaged\n",
    "    l.append(lp1) # l is a list of sublists where each sublist is the lp1 of a path\n",
    "    l3+=lp1 # list with all the averaged files in all the paths considered\n",
    "    l2+= l2p1     # list of all the directories of the averaged files in the paths considered\n",
    "\n",
    "d = dict(zip(l3, map(pd.read_table, l2))) # dictionary assigning to each averaged file the corresponding results table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Density per microns squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mole= {} # dictionary assigning to each path a the mean density of molecules averaged between all the data taken in the path\n",
    "density= {}\n",
    "for i in range(number_paths):\n",
    "    j,m= 0,[] \n",
    "    for file in l[i]: #looping over each averaged file in the path\n",
    "        j+=1 # the number of the averaged file considered in the path \n",
    "        x_values = list(d[file]['X_(nm)']) # x_values extracted from the results table of the file\n",
    "        y_values = list(d[file]['Y_(nm)']) #y_values\n",
    "        bins_x = int(max([int(l) for l in x_values])/length_nm) #dividing the x_axis into intervals of 30nm\n",
    "        bins_y = int(max([int(l) for l in y_values])/length_nm) #same for y_axis to get bins/pixels of 30nm by 30nm\n",
    "        returns = plt.hist2d(x_values, y_values, bins = (bins_x, bins_y), cmap =\"gray\") \n",
    "        # returns plots a 2D histogram of the averaged image and extracts the number of molecules per pixel/bin as its 0th arg\n",
    "        plt.title(list(paths.keys())[i]+\": data \"+str(j), fontweight =\"bold\") \n",
    "        #plots the 2D histogram.. remove the plt.close() at the end to get the histograms\n",
    "        density[file] = [[int(bool(i)) for i in returns[0][j]] for j in range(bins_x)] \n",
    "        #density is a dictionary assigning to each averaged file in the path a list of sublists where the pixel (i,j) get a 0 value if it has no molcules and 1 otherwise \n",
    "        m.append(len(d[file])/(sum(sum(i) for i in density[file])*(max(x_values)*0.001*max(y_values)*0.001/(bins_y*bins_x))))\n",
    "        # m is a list of in which the number of molecules/(surface of pixels containing at least 1 molecule (in microns))\n",
    "    mean_mole[list(paths.keys())[i]] =np.mean(m) # the average of the densities of all the averaged files in the path is calculated\n",
    "plt.close() \n",
    "\n",
    "print('Mean density of molecules per micron squared:', mean_mole);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNR distribution per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxfreIt = {} \n",
    "for name, df in d.items(): # looping over each averaged file (name) and its result table (df)\n",
    "    idxiter = [i for i in range(1,40)] # List of all the values of the SNR we are considering (from 1 to 40)\n",
    "    idxfreIt[name] = (idxiter, [((df['SNR']> 0) &(df['SNR']>= idxiter[i]) &  (df['SNR'] < idxiter[i+1])).sum() for i in range(0, len(idxiter)-1) ])\n",
    "    # For the ith value of SNR in idxiter, we count the number of molecules having an SNR greater or equal to it and strictly less than the value idxiter[i+1]\n",
    "    # we assign to idxfreIt[name] a tuple with the first argument the list idxiter and the second argument the list of the values calculated\n",
    "    \n",
    "    \n",
    "m=0 \n",
    "for i in range(number_paths): # Looping over the paths\n",
    "    j=0 \n",
    "    f = plt.figure()\n",
    "    for name in l[i]: # Looping over the averaged files in the path\n",
    "        j+=1 # Number of the avergaed file considered in the path\n",
    "        plt.bar(idxfreIt[name][0][:-1],np.array([idxfreIt[name][1][i]/len(d[list(d.keys())[m]]) for i in range(len(idxfreIt[name][1]))]), width = 0.6, label = \"data \"+ str(j))\n",
    "        # We make a bar plot with the SNR values (idxiter) as the x-value and the corresponding number of molecules (calculated above), divided by the total number of molecules, as the y-value\n",
    "        plt.title(list(paths.keys())[i]) \n",
    "        plt.xlabel(\"SNR\")\n",
    "        plt.ylabel(\"Fraction of Frames\")\n",
    "        plt.xlim([0,40])\n",
    "        plt.legend()\n",
    "        m+=1 # Number of the averaged file considered (-1)\n",
    "    #uncomment next line to save the plot\n",
    "    #plt.savefig(list(paths.keys())[i] +'SNR'+ '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean SNR distribution per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxfreIt = {}\n",
    "m=0\n",
    "for i in range(number_paths): # Looping over the paths\n",
    "    idxiter = [j for j in range(1,40)] # List of all the values of the SNR we are considering (from 1 to 40)\n",
    "    elmt = [(d[l[i][j]]['SNR']> 0).sum() for j in range(len(l[i]))] \n",
    "    # creating a list of sublists. Each sublist contains the values of the SNR greater than 0 in one of the averaged files in the path.\n",
    "    idxfreIt[list(paths.keys())[i]] = (idxiter, [np.mean([((d[l[i][j]]['SNR']> 0) & (d[l[i][j]]['SNR']>= idxiter[k]) & (d[l[i][j]]['SNR'] < idxiter[k+1])).sum()/elmt[j] for j in range(len(l[i]))]) for k in range(0, len(idxiter)-1)])\n",
    "    # For the ith SNR value, for each averaged file, we calculate the number of molecules having an SNR between idxiter[i] and idxiter[i+1]\n",
    "    # This value is normalized by the total number of molecules having a positive SNR in the averaged file.\n",
    "    # The average is taken between all the average files\n",
    "    m+=len(l[i]) # Number of the first file in a path\n",
    "    \n",
    "for i in range(number_paths):\n",
    "    f = plt.figure()\n",
    "    plt.bar(idxfreIt[list(paths.keys())[i]][0][:-1],height = np.array([idxfreIt[list(paths.keys())[i]][1][k] for k in range(len(idxfreIt[list(paths.keys())[i]][1]))]), width = 0.6, label = 'mean')\n",
    "    # We make a bar plot with with the x-components the values of the SNR considered above (idxiter) and the y-components the corresponding averaged and normalized number of molecules calculated above\n",
    "    plt.title(list(paths.keys())[i])\n",
    "    plt.xlabel(\"SNR\")\n",
    "    plt.ylabel(\"Fraction of Frames\")\n",
    "    plt.xlim([0,40])\n",
    "    plt.legend()\n",
    "    #uncomment next line to save the plot\n",
    "    #plt.savefig(list(paths.keys())[i] +'Average Distribution of the SNR'+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean SNR per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR = {} \n",
    "for i in range(number_paths): # Looping over the paths\n",
    "    li=[]\n",
    "    for name in l[i]: # Looping over the averaged files in the path considered\n",
    "        li.append(np.mean([d[name]['SNR'][s] for s in range(len(d[name])) if d[name]['SNR'][s]>0]))\n",
    "        # li is a containing the average of the SNR values of all molecules for each average file\n",
    "    SNR[list(paths.keys())[i]] = float(\"{:.2f}\". format(np.mean(li)))\n",
    "    # The SNR dictionary assigns to the path considered the mean of li, i.e. the mean of the averaged SNR between the data \n",
    "\n",
    "    \n",
    "print('Mean SNR per dataset: ', SNR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantification of SNR decay per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxfreIt = {}\n",
    "m=0\n",
    "for i in range(number_paths): # Looping over the paths\n",
    "    idxiter = [j for j in range(20,41,20)] # Considering the SNR values between 20 and 41 and with an interval of 20, i.e. considering the interval [20,40]\n",
    "    elmt = [(d[l[i][j]]['SNR']> 0).sum() for j in range(len(l[i]))] # same as in the \"SNR distribution per dataset cell\" but only for molecules in the interval of SNR considered\n",
    "    idxfreIt[list(paths.keys())[i]] = (idxiter, [np.mean([((d[l[i][j]]['SNR']> 0) & (d[l[i][j]]['SNR']>= idxiter[k]) & (d[l[i][j]]['SNR'] < idxiter[k+1])).sum()/elmt[j] for j in range(len(l[i]))]) for k in range(0, len(idxiter)-1)])\n",
    "    # same as in the \"SNR distribution per dataset cell\"\n",
    "    m+=len(l[i]) # same as in the \"SNR distribution per dataset cell\"\n",
    "    \n",
    "print('Fraction of molecules with SNR between 20 and 40')\n",
    "for i in range(number_paths): # Looping over the paths\n",
    "    print(list(paths.keys())[i], np.array([idxfreIt[list(paths.keys())[i]][1][k] for k in range(len(idxfreIt[list(paths.keys())[i]][1]))])[idxfreIt[list(paths.keys())[i]][0][:-1].index(20)])\n",
    "    # printing the average fraction of molecules with and SNR between 20 and 40 that was calculated above in the second argument of idxfreIt\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density as a function of the SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndexes(table, value): # function that returns the index of the first molecule having a \n",
    "    result = table.isin([value])\n",
    "    return list(result['SNR'][result['SNR'] == True].index)\n",
    "\n",
    "idx = {}\n",
    "for name, df in d.items():\n",
    "    idx[name] = (range(0, 70,5), [(df['SNR']>= i).sum() for i in range(0, 70,5)])\n",
    "\n",
    "idxcnt = {}\n",
    "for name, ids in idx.items():\n",
    "    idxcnt[name] = (ids, [len(getIndexes(d[name], i)) for i in ids])\n",
    "    \n",
    "plt.figure() \n",
    "for i in range(number_paths):\n",
    "        plt.plot(idx[l[i][0]][0], [np.mean([idx[name][1][j]/(sum(sum(i) for i in density[name])*(max(list(d[name]['X_(nm)']))*0.001*max(list(d[name]['Y_(nm)']))*0.001/(bins_y*bins_x))) for name in l[i]]) for j in range(len(idx[l[i][0]][0]))], '--', label = list(paths.keys())[i])\n",
    "plt.legend()\n",
    "plt.xlabel(\"SNR\")\n",
    "plt.xlim([0,50])\n",
    "plt.ylabel(\"Density (molecules/microns^2)\")\n",
    "#uncomment next line to save the plot\n",
    "#plt.savefig(\"All data DTT-sodium sulfite Density as a function of the SNR\"+ '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photon Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Photon Count distribution per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do the exact same thing as previously done for the SNR with the variations indicated in comments\n",
    "idxfreIt = {}\n",
    "for name, df in d.items():\n",
    "    idxiter = [i for i in range(1,6000,250)] # The values of photon count considered are between 1 and 6000 and with intervals of 500 \n",
    "    idxfreIt[name] = (idxiter, [((df['IntegratedInt']>= 0) & (df['IntegratedInt']>= idxiter[i]) & (df['IntegratedInt'] < idxiter[i+1])).sum() for i in range(0, len(idxiter)-1)])    \n",
    "\n",
    "m=0\n",
    "for i in range(number_paths):\n",
    "    j=0\n",
    "    f = plt.figure()\n",
    "    for name in l[i]:\n",
    "        j+=1\n",
    "        plt.bar(idxfreIt[name][0][:-1],height = np.array([idxfreIt[name][1][k]/len(d[list(d.keys())[m]]) for k in range(len(idxfreIt[name][1]))]), width = 400, label = \"data \"+ str(j))\n",
    "        plt.title(list(paths.keys())[i])\n",
    "        plt.xlabel(\"Photon Count\")\n",
    "        plt.ylabel(\"Fraction of Frames\")\n",
    "        plt.xlim([0,6000])\n",
    "        plt.legend()\n",
    "        m+=1\n",
    "    #uncomment next line to save the plot\n",
    "    #plt.savefig(list(paths.keys())[i] +'Distribution of the photon count'+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Photon Count distribution per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do the exact same thing as done previously with the SNR\n",
    "idxfreIt = {}\n",
    "m=0\n",
    "for i in range(number_paths):\n",
    "    idxiter = [j for j in range(1,6000,250)]\n",
    "    elmt = [(d[l[i][j]]['IntegratedInt']> 0).sum() for j in range(len(l[i]))]\n",
    "    idxfreIt[list(paths.keys())[i]] = (idxiter, [np.mean([((d[l[i][j]]['IntegratedInt']> 0) & (d[l[i][j]]['IntegratedInt']>= idxiter[k]) & (d[l[i][j]]['IntegratedInt'] < idxiter[k+1])).sum()/elmt[j] for j in range(len(l[i]))]) for k in range(0, len(idxiter)-1)])\n",
    "    m+=len(l[i])\n",
    "\n",
    "for i in range(number_paths):\n",
    "    f = plt.figure()\n",
    "    plt.bar(idxfreIt[list(paths.keys())[i]][0][:-1],height = np.array([idxfreIt[list(paths.keys())[i]][1][k] for k in range(len(idxfreIt[list(paths.keys())[i]][1]))]), width = 200, label = 'mean')\n",
    "    plt.title(list(paths.keys())[i])\n",
    "    plt.xlabel(\"Photon Count\")\n",
    "    plt.ylabel(\"Fraction of Frames\")\n",
    "    plt.xlim([-250,5000])\n",
    "    plt.legend()  \n",
    "    #uncomment next line to save the plot\n",
    "    #plt.savefig(list(paths.keys())[i] +'Average Distribution of the photon count'+'.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean photon count per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do the exact same thing as done previously with the SNR\n",
    "Integrated_int = {}\n",
    "for i in range(number_paths):\n",
    "    li=[]\n",
    "    for name in l[i]:\n",
    "        li.append(np.mean([d[name]['IntegratedInt'][s] for s in range(len(d[name])) if d[name]['IntegratedInt'][s]>0]))\n",
    "    Integrated_int[list(paths.keys())[i]] = float(\"{:.2f}\". format(np.mean(li)))   \n",
    "\n",
    "print('Integrated_int: ', Integrated_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantification of the photon count decay per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do the exact same thing as done previously with the SNR. The variations are indicated in comments.\n",
    "idxfreIt = {}\n",
    "m=0\n",
    "for i in range(number_paths):\n",
    "    idxiter = [j for j in range(2000,6001,4000)] #This time we consider the molecules with a photon count between 2000 and 6000\n",
    "    elmt = [(d[l[i][j]]['IntegratedInt']> 0).sum() for j in range(len(l[i]))]\n",
    "    idxfreIt[list(paths.keys())[i]] = (idxiter, [np.mean([((d[l[i][j]]['IntegratedInt']> 0) & (d[l[i][j]]['IntegratedInt']>= idxiter[k]) & (d[l[i][j]]['IntegratedInt'] < idxiter[k+1])).sum()/elmt[j] for j in range(len(l[i]))]) for k in range(0, len(idxiter)-1)])\n",
    "    m+=len(l[i])\n",
    "\n",
    "print('probability for photon count between 2000 and 6000')\n",
    "for i in range(number_paths):\n",
    "    print(list(paths.keys())[i], np.array([idxfreIt[list(paths.keys())[i]][1][k] for k in range(len(idxfreIt[list(paths.keys())[i]][1]))])[idxfreIt[list(paths.keys())[i]][0][:-1].index(2000)])\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the cell calculating the mean of the parameter considered should be run first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D histogram of the SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_val = list(SNR.values()) # creating a list of all the SNR values in order\n",
    "x_grid = np.arange(min(x_list)-5*x_spacing,max(x_list)+5*x_spacing,x_spacing)\n",
    "#creating a grid going from the minimal value in the x degree of freedom -5*x_spacing to the maximal value+5*x_spacing and with intervals of x_spacing\n",
    "y_grid = np.arange(min(y_list)-5*y_spacing,max(y_list)+5*y_spacing,y_spacing) # Same done with a y grid\n",
    "[x_grid,y_grid] = np.meshgrid(x_grid,y_grid) # creation of a meshgrid between the 2 grids\n",
    "z_grid = griddata((x_list,y_list), SNR_val, (x_grid, y_grid)) # the values (x,y) are assigned their SNR values\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111) \n",
    "plt.contourf(x_grid,y_grid,z_grid)\n",
    "plt.plot(x_list,y_list, 'k.') #plotting the 2D histogram\n",
    "plt.xlabel(x_label + ' ('+x_unit+')')  \n",
    "plt.ylabel(y_label + ' ('+y_unit+')') \n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('SNR')\n",
    "#uncomment next line to save the plot\n",
    "#plt.savefig(list(paths.keys())[i] +'SNR histogram'+ '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D histogram of the density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do with the density as previously done with the SNR\n",
    "Dens = list(mean_mole.values())\n",
    "x_grid = np.arange(min(x_list)-5*x_spacing,max(x_list)+5*x_spacing,x_spacing)\n",
    "y_grid = np.arange(min(y_list)-5*y_spacing,max(y_list)+5*y_spacing,y_spacing)\n",
    "[x_grid,y_grid] = np.meshgrid(x_grid,y_grid)\n",
    "z_grid = griddata((x_list,y_list), Dens, (x_grid, y_grid))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.contourf(x_grid,y_grid,z_grid)\n",
    "plt.plot(x_list,y_list, 'k.')\n",
    "plt.xlabel(x_label + ' ('+x_unit+')')  \n",
    "plt.ylabel(y_label + ' ('+y_unit+')') \n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('Density (molecules/micron^2)')\n",
    "#uncomment next line to save the plot\n",
    "#plt.savefig(list(paths.keys())[i] +'Density 2D histogram DTT-Sodium Sulfite'+ '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D histogram of the photon count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do the same with the integrated intensity as previously done with the SNR\n",
    "Int_val = list(Integrated_int.values())\n",
    "x_grid = np.arange(min(x_list)-5*x_spacing,max(x_list)+5*x_spacing,x_spacing)\n",
    "y_grid = np.arange(min(y_list)-5*y_spacing,max(y_list)+5*y_spacing,y_spacing)\n",
    "[x_grid,y_grid] = np.meshgrid(x_grid,y_grid)\n",
    "z_grid = griddata((x_list,y_list), Int_val, (x_grid, y_grid))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.contourf(x_grid,y_grid,z_grid)\n",
    "plt.plot(x_list,y_list, 'k.')\n",
    "plt.xlabel(x_label + ' ('+x_unit+')')  \n",
    "plt.ylabel(y_label + ' ('+y_unit+')') \n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('Photon Count (photons)')\n",
    "#uncomment next line to save the plot\n",
    "#plt.savefig(list(paths.keys())[i] +'Photon Count 2D histogram'+ '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
