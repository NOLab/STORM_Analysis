{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of \"DOM_dedrift\" files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the dictionary with the values being the folders containing the datasets (each value is the path of the folder corresponding to one type of buffer and containing all the data associated to it). Note that the macro script should be run on the folder before using this code. The keys of the dictionary are the names you would like to give to the directories (label of the buffers).\n",
    "paths = {}\n",
    "# indicate the size of te pixels you want to compute the density (in nanometers)\n",
    "length_nm = 0\n",
    "#indicate the value of the first degree of freedom for each data\n",
    "x_list = []\n",
    "#indicate the value of the second degree of freedom for each data (in the same order)\n",
    "y_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell and then the cells of the codes you are interested in. Note that you can save the plots by uncommenting the last line of the cell you are considering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "import math\n",
    "import scipy.stats\n",
    "import statistics\n",
    "from scipy.stats import gamma, lognorm, halflogistic, foldcauchy, exponnorm\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import halfnorm\n",
    "from scipy.interpolate import griddata\n",
    "import scipy.integrate as integrate\n",
    "import os\n",
    "import re\n",
    "\n",
    "number_paths = len(paths) \n",
    "\n",
    "\n",
    "l, l2, l3 = [], [], [] \n",
    "for path in list(paths.values()): \n",
    "    lp1 = os.listdir(path) \n",
    "    lp1 = list(filter(lambda x: x.endswith('avg.xls'), lp1))\n",
    "    l2p1 = [os.path.join(path, f) for f in lp1]\n",
    "    l.append(lp1)\n",
    "    l3+=lp1\n",
    "    l2+= l2p1    \n",
    "\n",
    "d = dict(zip(l3, map(pd.read_table, l2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Density per microns squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "l, l2, l3 = [], [], [] \n",
    "for path in list(paths.values()): \n",
    "    lp1 = os.listdir(path) \n",
    "    lp1 = list(filter(lambda x: x.endswith('avg.xls'), lp1))\n",
    "    l2p1 = [os.path.join(path, f) for f in lp1]\n",
    "    l.append(lp1)\n",
    "    l3+=lp1\n",
    "    l2+= l2p1  \n",
    "d = dict(zip(l3, map(pd.read_table, l2)))\n",
    "\n",
    "mean_mole= {}\n",
    "density= {}\n",
    "for i in range(number_paths):\n",
    "    j,m= 0,[]\n",
    "    for file in l[i]:\n",
    "        j+=1\n",
    "        x_values = list(d[file]['X_(nm)'])\n",
    "        y_values = list(d[file]['Y_(nm)'])\n",
    "        bins_x = int(max([int(l) for l in x_values])/length_nm)\n",
    "        bins_y = int(max([int(l) for l in y_values])/length_nm)\n",
    "        returns = plt.hist2d(x_values, y_values, bins = (bins_x, bins_y), cmap =\"gray\")\n",
    "        plt.title(list(paths.keys())[i]+\": data \"+str(j), fontweight =\"bold\")\n",
    "        density[file] = [[int(bool(i)) for i in returns[0][j]] for j in range(bins_x)]\n",
    "        m.append(len(d[file])/(sum(sum(i) for i in density[file])*(max(x_values)*0.001*max(y_values)*0.001/(bins_y*bins_x))))\n",
    "    mean_mole[list(paths.keys())[i]] =np.mean(m)\n",
    "plt.close()\n",
    "\n",
    "print('Mean density of molecules per micron squared:', mean_mole);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNR distribution per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxfreIt = {}\n",
    "for name, df in d.items():\n",
    "    idxiter = [i for i in range(1,40)]\n",
    "    idxfreIt[name] = (idxiter, [((df['SNR']> 0) &(df['SNR']>= idxiter[i]) &  (df['SNR'] < idxiter[i+1])).sum() for i in range(0, len(idxiter)-1) ])\n",
    "\n",
    "    \n",
    "m=0\n",
    "for i in range(number_paths):\n",
    "    j=0\n",
    "    f = plt.figure()\n",
    "    for name in l[i]:\n",
    "        j+=1\n",
    "        plt.bar(idxfreIt[name][0][:-1],np.array([idxfreIt[name][1][i]/len(d[list(d.keys())[m]]) for i in range(len(idxfreIt[name][1]))]), width = 0.6, label = \"data \"+ str(j))\n",
    "        plt.title(list(paths.keys())[i])\n",
    "        plt.xlabel(\"SNR\")\n",
    "        plt.ylabel(\"Fraction of Frames\")\n",
    "        plt.xlim([0,40])\n",
    "        plt.legend()\n",
    "        m+=1\n",
    "    #uncomment next line to save the plot\n",
    "    #plt.savefig(list(paths.keys())[i] +'SNR'+ '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean SNR distribution per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxfreIt = {}\n",
    "m=0\n",
    "for i in range(number_paths):\n",
    "    idxiter = [j for j in range(1,40)]\n",
    "    idxfreIt[list(paths.keys())[i]] = (idxiter, [np.mean([((d[l[i][j]]['SNR']> 0) & (d[l[i][j]]['SNR']>= idxiter[k]) & (d[l[i][j]]['SNR'] < idxiter[k+1])).sum()/len(d[list(d.keys())[m+j]]) for j in range(len(l[i]))]) for k in range(0, len(idxiter)-1)])\n",
    "    m+=len(l[i])\n",
    "    \n",
    "for i in range(number_paths):\n",
    "    f = plt.figure()\n",
    "    plt.bar(idxfreIt[list(paths.keys())[i]][0][:-1],height = np.array([idxfreIt[list(paths.keys())[i]][1][k] for k in range(len(idxfreIt[list(paths.keys())[i]][1]))]), width = 0.6, label = 'mean')\n",
    "    plt.title(list(paths.keys())[i])\n",
    "    plt.xlabel(\"SNR\")\n",
    "    plt.ylabel(\"Fraction of Frames\")\n",
    "    plt.xlim([0,40])\n",
    "    plt.legend()\n",
    "    #uncomment next line to save the plot\n",
    "    #plt.savefig(list(paths.keys())[i] +'Average Distribution of the SNR'+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean SNR per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la, l2a, l3a = [], [], [] \n",
    "for path in list(paths.values()): \n",
    "    lp1 = os.listdir(path) \n",
    "    lp1 = list(filter(lambda x: x.endswith('dedrift.xls'), lp1))\n",
    "    l2p1 = [os.path.join(path, f) for f in lp1]\n",
    "    la.append(lp1)\n",
    "    l3a+=lp1\n",
    "    l2a+= l2p1    \n",
    "\n",
    "da = dict(zip(l3a, map(pd.read_table, l2a)))\n",
    "\n",
    "\n",
    "SNR = {}\n",
    "for i in range(number_paths):\n",
    "    li=[]\n",
    "    for name in l[i]:\n",
    "        li.append(np.mean([d[name]['SNR'][s] for s in range(len(d[name]))]))\n",
    "    SNR[list(paths.keys())[i]] = float(\"{:.2f}\". format(np.mean(li)))\n",
    "\n",
    "    \n",
    "print('Mean SNR per dataset: ', SNR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantification of SNR decay per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxfreIt = {}\n",
    "m=0\n",
    "for i in range(number_paths):\n",
    "    idxiter = [j for j in range(1,40,5)]\n",
    "    idxfreIt[list(paths.keys())[i]] = (idxiter, [np.mean([((d[l[i][j]]['SNR']> 0) & (d[l[i][j]]['SNR']>= idxiter[k]) & (d[l[i][j]]['SNR'] < idxiter[k+1])).sum()/len(d[list(d.keys())[m+j]]) for j in range(len(l[i]))]) for k in range(0, len(idxiter)-1)])\n",
    "    m+=len(l[i])\n",
    "print('Fraction of molecules with SNR between 11 and 16')\n",
    "for i in range(number_paths):\n",
    "    print(list(paths.keys())[i], np.array([idxfreIt[list(paths.keys())[i]][1][k] for k in range(len(idxfreIt[list(paths.keys())[i]][1]))])[idxfreIt[list(paths.keys())[i]][0][:-1].index(11)])\n",
    "print('')\n",
    "\n",
    "print('Fraction of molecules with SNR between 21 and 26')\n",
    "for i in range(number_paths):\n",
    "    print(list(paths.keys())[i], np.array([idxfreIt[list(paths.keys())[i]][1][k] for k in range(len(idxfreIt[list(paths.keys())[i]][1]))])[idxfreIt[list(paths.keys())[i]][0][:-1].index(21)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density as a function of the SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndexes(table, value): \n",
    "    result = table.isin([value])\n",
    "    return list(result['SNR'][result['SNR'] == True].index)\n",
    "\n",
    "idx = {}\n",
    "for name, df in d.items():\n",
    "    idx[name] = (range(0, 70,5), [(df['SNR']>= i).sum() for i in range(0, 70,5)])\n",
    "\n",
    "idxcnt = {}\n",
    "for name, ids in idx.items():\n",
    "    idxcnt[name] = (ids, [len(getIndexes(d[name], i)) for i in ids])\n",
    "    \n",
    "plt.figure() \n",
    "for i in range(number_paths):\n",
    "        plt.plot(idx[l[i][0]][0], [np.mean([idx[name][1][j]/(sum(sum(i) for i in density[name])*(max(list(d[name]['X_(nm)']))*0.001*max(list(d[name]['Y_(nm)']))*0.001/(bins_y*bins_x))) for name in l[i]]) for j in range(len(idx[l[i][0]][0]))], '--', label = list(paths.keys())[i])\n",
    "plt.legend()\n",
    "plt.xlabel(\"SNR\")\n",
    "plt.xlim([0,50])\n",
    "plt.ylabel(\"Density (molecules/microns^2)\")\n",
    "#uncomment next line to save the plot\n",
    "#plt.savefig(\"All data DTT-sodium sulfite Density as a function of the SNR\"+ '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photon Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Photon Count distribution per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idxfreIt = {}\n",
    "for name, df in d.items():\n",
    "    idxiter = [i for i in range(1,math.ceil(max(df['IntegratedInt'])),500)]\n",
    "    idxfreIt[name] = (idxiter, [((df['IntegratedInt']>= 0) & (df['IntegratedInt']>= idxiter[i]) & (df['IntegratedInt'] < idxiter[i+1])).sum() for i in range(0, len(idxiter)-1)])    \n",
    "\n",
    "m=0\n",
    "for i in range(number_paths):\n",
    "    j=0\n",
    "    f = plt.figure()\n",
    "    for name in l[i]:\n",
    "        j+=1\n",
    "        plt.bar(idxfreIt[name][0][:-1],height = np.array([idxfreIt[name][1][k]/len(d[list(d.keys())[m]]) for k in range(len(idxfreIt[name][1]))]), width = 400, label = \"data \"+ str(j))\n",
    "        plt.title(list(paths.keys())[i])\n",
    "        plt.xlabel(\"Photon Count\")\n",
    "        plt.ylabel(\"Fraction of Frames\")\n",
    "        plt.xlim([0,6000])\n",
    "        plt.legend()\n",
    "        m+=1\n",
    "    #uncomment next line to save the plot\n",
    "    #plt.savefig(list(paths.keys())[i] +'Distribution of the photon count'+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Photon Count distribution per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxfreIt = {}\n",
    "m=0\n",
    "for i in range(number_paths):\n",
    "    idxiter = [j for j in range(1,6000,250)]\n",
    "    idxfreIt[list(paths.keys())[i]] = (idxiter, [np.mean([((d[l[i][j]]['IntegratedInt']> 0) & (d[l[i][j]]['IntegratedInt']>= idxiter[k]) & (d[l[i][j]]['IntegratedInt'] < idxiter[k+1])).sum()/len(d[list(d.keys())[m+j]]) for j in range(len(l[i]))]) for k in range(0, len(idxiter)-1)])\n",
    "    m+=len(l[i])\n",
    "\n",
    "for i in range(number_paths):\n",
    "    f = plt.figure()\n",
    "    plt.bar(idxfreIt[list(paths.keys())[i]][0][:-1],height = np.array([idxfreIt[list(paths.keys())[i]][1][k] for k in range(len(idxfreIt[list(paths.keys())[i]][1]))]), width = 200, label = 'mean')\n",
    "    plt.title(list(paths.keys())[i])\n",
    "    plt.xlabel(\"Photon Count\")\n",
    "    plt.ylabel(\"Fraction of Frames\")\n",
    "    plt.xlim([-250,5000])\n",
    "    plt.legend()  \n",
    "    #uncomment next line to save the plot\n",
    "    #plt.savefig(list(paths.keys())[i] +'Average Distribution of the photon count'+'.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean photon count per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la, l2a, l3a = [], [], [] \n",
    "for path in list(paths.values()): \n",
    "    lp1 = os.listdir(path) \n",
    "    lp1 = list(filter(lambda x: x.endswith('dedrift.xls'), lp1))\n",
    "    l2p1 = [os.path.join(path, f) for f in lp1]\n",
    "    la.append(lp1)\n",
    "    l3a+=lp1\n",
    "    l2a+= l2p1    \n",
    "\n",
    "da = dict(zip(l3a, map(pd.read_table, l2a)))\n",
    "\n",
    "Integrated_int = {}\n",
    "for i in range(number_paths):\n",
    "    li=[]\n",
    "    for name in l[i]:\n",
    "        li.append(np.mean([d[name]['IntegratedInt'][s] for s in range(len(d[name])) if d[name]['IntegratedInt'][s]>0]))\n",
    "    Integrated_int[list(paths.keys())[i]] = float(\"{:.2f}\". format(np.mean(li)))\n",
    "    \n",
    "\n",
    "print('Integrated_int: ', Integrated_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantification of the photon count decay per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxfreIt = {}\n",
    "m=0\n",
    "for i in range(number_paths):\n",
    "    idxiter = [j for j in range(0,6000,500)]\n",
    "    idxfreIt[list(paths.keys())[i]] = (idxiter, [np.mean([((d[l[i][j]]['IntegratedInt']> 0) & (d[l[i][j]]['IntegratedInt']>= idxiter[k]) & (d[l[i][j]]['IntegratedInt'] < idxiter[k+1])).sum()/len(d[list(d.keys())[m+j]]) for j in range(len(l[i]))]) for k in range(0, len(idxiter)-1)])\n",
    "    m+=len(l[i])\n",
    "    \n",
    "print('probability for photon count between 3000 and 3500')\n",
    "for i in range(number_paths):\n",
    "    print(list(paths.keys())[i], np.array([idxfreIt[list(paths.keys())[i]][1][k] for k in range(len(idxfreIt[list(paths.keys())[i]][1]))])[idxfreIt[list(paths.keys())[i]][0][:-1].index(3000)])\n",
    "print('')\n",
    "\n",
    "print('probability for photon count between 4000 and 4500')\n",
    "for i in range(number_paths):\n",
    "    print(list(paths.keys())[i], np.array([idxfreIt[list(paths.keys())[i]][1][k] for k in range(len(idxfreIt[list(paths.keys())[i]][1]))])[idxfreIt[list(paths.keys())[i]][0][:-1].index(4000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D histogram for the SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_list\n",
    "y = y_list\n",
    "SNR_val = list(SNR.values())\n",
    "x_grid = np.arange(min(x_list)-5,max(x_list)+5,1)#rechange as needed \n",
    "y_grid = np.arange(min(y_list)-5,max(y_list)+5,1)#rechange as needed \n",
    "[x_grid,y_grid] = np.meshgrid(x_grid,y_grid)\n",
    "z_grid = griddata((x,y), SNR_val, (x_grid, y_grid))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.contourf(x_grid,y_grid,z_grid)\n",
    "plt.plot(x,y, 'k.')\n",
    "plt.xlabel('DTT')#rechange as needed \n",
    "plt.ylabel('Sodium Sulfite')#rechange as needed \n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('SNR')\n",
    "#uncomment next line to save the plot\n",
    "#plt.savefig(list(paths.keys())[i] +'SNR 2D histogram DTT-SS'+ '.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D histogram for the photon count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_list\n",
    "y = y_list\n",
    "Int_val = list(mean_mole.values())\n",
    "x_grid = np.arange(min(x_list)-5,max(x_list)+5,1)#rechange as needed \n",
    "y_grid = np.arange(min(y_list)-5,max(y_list)+5,1)#rechange as needed \n",
    "[x_grid,y_grid] = np.meshgrid(x_grid,y_grid)\n",
    "z_grid = griddata((x,y), Int_val, (x_grid, y_grid))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.contourf(x_grid,y_grid,z_grid)\n",
    "plt.plot(x,y, 'k.')\n",
    "plt.xlabel('DTT')#rechange as needed \n",
    "plt.ylabel('Sodium Sulfite')#rechange as needed \n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('Density')\n",
    "#uncomment next line to save the plot\n",
    "#plt.savefig(list(paths.keys())[i] +'Density 2D histogram DTT-SS'+ '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
